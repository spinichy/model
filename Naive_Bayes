## Step.1 Data collection

data_raw <- readLines(con = "SMSSpamCollection.txt")
str(data_raw)
head(data_raw);tail(data_raw)


## Step.2 Data processing and exploration


#split text data
library(tidyverse)
n <- length(data_raw)
type <- c()
text <- c()
data_raw

for(i in 1:n) {
  result <- unlist(str_split(string = data_raw[i], pattern = "\\\t"))
  type[i] <- result[1]
  text[i] <- result[2]
}
data_1 <- data.frame(
  type = type,
  text = text
)

data_1$type <- factor(data_1$type)

str(data_1)
table(data_1$type)

#text corpus
install.packages('tm') #updated
library(tm)

text_corpus <- VectorSource(x = data_1$text) %>% 
  VCorpus()

inspect(head(text_corpus))
text_corpus[[1]] %>% 
  as.character()

#change lower case
text_corpus_clean_1 <- tm_map(x = text_corpus, 
                            FUN = content_transformer(FUN = tolower))

#remove numbers
text_corpus_clean_2 <- tm_map(x = text_corpus_clean_1,
                              FUN = removeNumbers)

#remove specific words
stopwords(kind = "en")
text_corpus_clean_3 <- tm_map(x = text_corpus_clean_2,
                              FUN = removeWords, stopwords())

#remove punctuaion
text_corpus_clean_4 <- tm_map(x = text_corpus_clean_3,
                              FUN = removePunctuation)

#stemming
library(SnowballC)
text_corpus_clean_5 <- tm_map(x = text_corpus_clean_4,
                              FUN = stemDocument)

#remove whitespace
text_corpus_clean_6 <- tm_map(x = text_corpus_clean_5,
                              FUN = stemDocument)
#processing check
text_corpus_clean_1[[1]] %>% 
  as.character()
text_corpus_clean_2[[1]] %>% 
  as.character()
text_corpus_clean_3[[1]] %>% 
  as.character()
text_corpus_clean_4[[1]] %>% 
  as.character()
text_corpus_clean_5[[1]] %>% 
  as.character()
text_corpus_clean_6[[1]] %>% 
  as.character()


#tokenization
text_DTM <- DocumentTermMatrix(text_corpus_clean_6)
inspect(text_DTM)

#Classify into training and testing data
train_index <- sample(x = 1:n, size = round(n*0.7), replace = FALSE)

DTM_train <- text_DTM[train_index,]
DTM_test <- text_DTM[-train_index,]

labels_train <- data_1$type[train_index]
labels_test <- data_1$type[-train_index]

table(labels_train) %>% 
  prop.table()
table(labels_test) %>% 
  prop.table()

#wordclous - text total
library(wordcloud)
windows()
wordcloud(words = text_corpus_clean_6, 
          min.freq = 50, 
          random.order = FALSE, scale = c(5,0.5))

index_ham <- which(data_1$type == "ham")
index_spam <- which(data_1$type == "spam")

#wordclous - text ham and text spam
windows()
wordcloud(words = text_corpus_clean_6[index_ham], 
          min.freq = 50, 
          random.order = FALSE, scale = c(5,0.5))
windows()
wordcloud(words = text_corpus_clean_6[index_spam], 
          min.freq = 10, 
          random.order = FALSE, scale = c(5,0.5))

#Frequnetly words
index_frequnet_words <- findFreqTerms(x = DTM_train, lowfreq = 5) 
DTM_train_freq <- DTM_train[,index_frequnet_words]
DTM_test_freq <- DTM_test[,index_frequnet_words]


#categorize function
fn_convert_counts <- function(x) {
  value <- ifelse(x > 0, "Yes", "No")
  return(value)
}

data_train_freq <- apply(X = DTM_train_freq, MARGIN = 2, FUN = fn_convert_counts) 
data_test_freq <- apply(X = DTM_test_freq, MARGIN = 2, FUN = fn_convert_counts) 
View(data_train_freq)



## Step.3 Train model 
library(naivebayes)
sms_classifier <- naive_bayes(x = data_train_freq, y = labels_train)



## Step.4 Evaluate model
pred_labels_test <- predict(object = sms_classifier, data_test_freq)

library(gmodels)
CrossTable(x = labels_test, y = pred_labels_test)



## Step.5 Improve model
sms_classifier_2 <- naive_bayes(x = data_train_freq, y = labels_train, laplace = 1)
pred_labels_test_2 <- predict(object = sms_classifier_2, data_test_freq)
CrossTable(x = labels_test, y = pred_labels_test_2)











##Step1. Data collection


library(mlbench)
?HouseVotes84

data("HouseVotes84")
votes <- HouseVotes84
str(votes)


##Step2. Data preparation and exploration


#NA exploration
library(mice)
md.pattern(x = votes)

library(tidyverse)
is.na(votes) %>% 
  as.data.frame() %>% 
  lapply(., sum) %>% 
  as.data.frame() #lots of NA value



#replace NA with random value
votes_replacement <- c()
for(i in 1:nrow(votes)) {
  class <- levels(votes$Class) #total class
  
  
  case_class <- votes[i,][,1] %>% 
    as.character()
  case_variables <- votes[i,][,-1] 
  
  
  df <- unlist(case_variables) %>% 
    table() %>% 
    prop.table() %>% 
    as.data.frame()
  prop_yes <- df[df$. == "y",][,2] #specific class probability
  
  if(is.na(prop_yes)) next
  
  other <- setdiff(class, case_class);other
  replacement_value <- sample(x = c(case_class, other), 
                              size = 1, 
                              prob = c(prop_yes, 1- prop_yes)) #extract random value
  replacement_result <- ifelse(test = case_class == replacement_value, "y", "n") 
  
  NA_index <- which(is.na(case_variables)) #find NA value
  case_variables[NA_index] <- replacement_result #replace NA with replacement_result
  
  case_variables_replacement <- cbind(case_class, case_variables)  %>% 
    as.data.frame()
  
  votes_replacement <- bind_rows(votes_replacement, case_variables_replacement)
}

str(votes_replacement) #249 row is All NA value
votes[249,]


#Split the data into training and testing sets

index_train <- sample(x = 1:nrow(votes_replacement), 
                      size = nrow(votes_replacement)*0.7, 
                      replace = FALSE)

votes_replacement_train <- votes_replacement[index_train,]
votes_replacement_test <- votes_replacement[-index_train,]


##Step3. Train Model
library(e1071)
votes_NB <- naiveBayes(case_class ~ ., data = votes_replacement_train);votes_NB


##Step4. Evaluate Model
real_votes <-  votes_replacement_test[,1]
pred_votes_NB <- predict(object = votes_NB, newdata =real_votes)
mean(pred_votes_NB ==  real_votes)

real_votes <-  votes_replacement_test[,1]
library(gmodels)
CrossTable(x = real_votes, 
           y = pred_votes_NB)

predict(object = votes_NB, 
        newdata = votes_replacement_test[,-1], 
        type = "class") #class
predict(object = votes_NB, 
        newdata = votes_replacement_test[,-1], 
        type = "raw") #probability


##Step5. Improve Model


votes_NB_laplace <- naiveBayes(case_class ~ ., data = votes_replacement_train, laplace = 1)

pred_votes_NB <- predict(object = votes_NB_laplace, newdata = votes_replacement_test[,-1])
mean(pred_votes_NB ==  real_votes)

CrossTable(x = real_votes, 
           y = pred_votes_NB)
